# turinCE - FSO Channel Power Estimation

## â­ NEW: Comprehensive Model Evaluation Framework (Task #82) â­

**Complete comparison of ALL models across multiple horizons with publication-quality visualizations!**

**Quick Start**: See [EVALUATION_QUICK_START.md](EVALUATION_QUICK_START.md)  
**Run Everything**: `python run_comprehensive_evaluation.py`

### What's Included
- âœ… **8 Models**: Naive, Linear Regression, Random Forest, XGBoost, LightGBM, LSTM, GRU, Transformer
- âœ… **4 Horizons**: 50, 100, 200, 500 samples (5-50ms prediction windows)
- âœ… **Comprehensive Metrics**: RMSE, MAE, RÂ², training time, inference speed, residual variance
- âœ… **6 Visualizations**: RMSE trends, speed/accuracy tradeoff, inference speed, variance, complexity, RÂ²
- âœ… **Detailed Report**: Best models per criterion, rankings, recommendations, insights
- âœ… **One Command**: Complete evaluation in 30-90 minutes

### Quick Example
```bash
# Run everything with default settings
python run_comprehensive_evaluation.py

# Or customize
python comprehensive_model_evaluation.py \
    --models xgboost lightgbm lstm \
    --horizons 50 100 200 500 \
    --output-dir my_results
```

### Output
```
results/
â”œâ”€â”€ comparison_table.csv                    # Complete results table
â”œâ”€â”€ evaluation_summary.md                   # Detailed findings & recommendations
â””â”€â”€ model_comparison_plots/
    â”œâ”€â”€ rmse_vs_horizon.png                # Primary comparison
    â”œâ”€â”€ training_time_vs_rmse.png          # Speed/accuracy tradeoff
    â”œâ”€â”€ inference_speed_comparison.png     # Deployment metrics
    â”œâ”€â”€ residual_variance_comparison.png   # Stability analysis
    â”œâ”€â”€ model_complexity_comparison.png    # Model size comparison
    â””â”€â”€ r2_score_comparison.png            # Explained variance
```

**See [EVALUATION_FRAMEWORK_README.md](EVALUATION_FRAMEWORK_README.md) for complete documentation**

---

## Deep Learning Models (LSTM, GRU, Transformer) ğŸš€

State-of-the-art deep learning architectures with PyTorch for time series forecasting!

**Quick Start**: See [deep_learning_README.md](deep_learning_README.md)  
**Run Evaluation**: `python run_deep_learning_evaluation.py --tune`

### Latest Features
- **LSTM** with bidirectional and unidirectional variants (1-3 layers)
- **GRU** with similar architecture flexibility
- **Transformer** with multi-head attention and positional encoding
- Sequence-to-point and sequence-to-sequence architectures
- Automatic hyperparameter tuning (random search)
- GPU/CPU compatibility with automatic detection
- Early stopping, learning rate scheduling, gradient clipping
- Model checkpointing and reproducibility

### Quick Example
```python
from data_preparation import load_turbulence_data
from config import get_config
from deep_learning_models import DeepLearningForecaster

# Load data
config = get_config('strong')
data, metadata = load_turbulence_data('strong', config)

# Create and train LSTM
forecaster = DeepLearningForecaster(
    model_type='lstm',
    lookback=100,
    horizon=50,
    use_gpu=True
)

datasets = forecaster.prepare_data(data)
forecaster.train(datasets['train'][0], datasets['train'][1],
                datasets['val'][0], datasets['val'][1])
result = forecaster.evaluate(datasets['test'][0], datasets['test'][1])
```

---

## Gradient Boosting Models (XGBoost & LightGBM) âš¡

Advanced gradient boosting implementations with comprehensive hyperparameter tuning and multi-horizon evaluation.

**Quick Start**: See [GRADIENT_BOOSTING_README.md](GRADIENT_BOOSTING_README.md)  
**Run Evaluation**: `python run_gradient_boosting_evaluation.py --tune`

### Features
- **XGBoost** regression with GPU acceleration support
- **LightGBM** regression optimized for large datasets
- Systematic hyperparameter tuning (50+ parameter combinations)
- Multi-horizon evaluation (50, 100, 200, 500 samples)
- Performance comparison vs Random Forest baseline
- Comprehensive metrics (RMSE, MAE, variance, timing)
- Feature importance analysis

### Quick Example
```python
from data_preparation import prepare_dataset
from gradient_boosting_models import train_and_evaluate_horizons

# Prepare datasets
datasets = prepare_dataset('strong')

# Train and evaluate XGBoost
results = train_and_evaluate_horizons(
    datasets,
    horizons=[50, 100, 200, 500],
    model_type='xgboost',
    tune_params=True
)
```

---

## Data Preparation Pipeline âœ¨

A comprehensive data preparation pipeline with 48+ features and multi-horizon support.

**Documentation**: See [data_pipeline_README.md](data_pipeline_README.md)  
**Examples**: Run `python example_usage.py`

### Key Features
- 5 prediction horizons (0.5ms to 50ms)
- 48+ engineered features (lagged, rolling, EMA, ACF, FFT, decomposition)
- Time-aware 70/15/15 train/val/test splits
- Flexible configuration system
- Complete documentation and examples

### Get Started
```python
from data_preparation import prepare_dataset
datasets = prepare_dataset('strong')
train_X, train_y = datasets[5]['train']
```

---

## Installation

### Core Dependencies
```bash
pip install numpy pandas scipy scikit-learn statsmodels matplotlib
```

### Deep Learning Models
```bash
pip install torch>=1.10.0
# Or use requirements file
pip install -r requirements_deep_learning.txt
```

### Gradient Boosting Models
```bash
pip install xgboost lightgbm
# Or use requirements file
pip install -r requirements_gradient_boosting.txt
```

### Verify Installation
```bash
python test_pipeline.py
```

---

## Project Structure

```
.
â”œâ”€â”€ config.py                                 # Configuration system
â”œâ”€â”€ data_preparation.py                       # Data pipeline (Task #77)
â”œâ”€â”€ deep_learning_models.py                   # LSTM, GRU, Transformer (Task #81)
â”œâ”€â”€ gradient_boosting_models.py               # XGBoost & LightGBM (Task #79)
â”œâ”€â”€ model_evaluation.py                       # Visualization & reporting utilities (Task #82)
â”œâ”€â”€ comprehensive_model_evaluation.py         # Unified evaluation script (Task #82) â­
â”œâ”€â”€ run_comprehensive_evaluation.py           # One-command evaluation pipeline (Task #82) â­
â”œâ”€â”€ run_deep_learning_evaluation.py           # Deep learning evaluation script
â”œâ”€â”€ run_gradient_boosting_evaluation.py       # Gradient boosting evaluation script
â”œâ”€â”€ example_usage.py                          # Usage examples
â”œâ”€â”€ test_pipeline.py                          # Verification tests
â”œâ”€â”€ deep_learning_README.md                   # Deep learning documentation
â”œâ”€â”€ GRADIENT_BOOSTING_README.md               # Gradient boosting documentation
â”œâ”€â”€ data_pipeline_README.md                   # Data pipeline documentation
â”œâ”€â”€ EVALUATION_FRAMEWORK_README.md            # Comprehensive evaluation guide (Task #82) â­
â”œâ”€â”€ EVALUATION_QUICK_START.md                 # Quick evaluation guide (Task #82) â­
â”œâ”€â”€ EXAMPLE_evaluation_summary.md             # Sample output format (Task #82) â­
â”œâ”€â”€ QUICK_START.md                            # Quick start guide
â”œâ”€â”€ IMPLEMENTATION_SUMMARY.md                 # Implementation details
â”œâ”€â”€ requirements_deep_learning.txt            # PyTorch dependencies
â”œâ”€â”€ requirements_gradient_boosting.txt        # XGBoost/LightGBM dependencies
â”œâ”€â”€ models/                                   # Saved model checkpoints
â””â”€â”€ results/                                  # Evaluation results (Task #82)
    â”œâ”€â”€ comparison_table.csv                  # Complete results table
    â”œâ”€â”€ evaluation_summary.md                 # Detailed findings report
    â””â”€â”€ model_comparison_plots/               # 6 visualization files
```

---

## Quick Links

### Documentation
- [â­ Comprehensive Evaluation](EVALUATION_FRAMEWORK_README.md) - Complete model comparison (Task #82)
- [â­ Evaluation Quick Start](EVALUATION_QUICK_START.md) - Fast evaluation guide (Task #82)
- [Deep Learning Models](deep_learning_README.md) - LSTM, GRU, Transformer implementation
- [Gradient Boosting Models](GRADIENT_BOOSTING_README.md) - XGBoost & LightGBM implementation
- [Data Pipeline](data_pipeline_README.md) - Feature engineering and data preparation
- [Quick Start Guide](QUICK_START.md) - Get up and running quickly
- [Implementation Summary](IMPLEMENTATION_SUMMARY.md) - Technical details

### Usage - Comprehensive Evaluation â­
- **Run everything**: `python run_comprehensive_evaluation.py`
- Custom models: `python comprehensive_model_evaluation.py --models xgboost lightgbm lstm`
- Fast evaluation: `python comprehensive_model_evaluation.py --models naive linear_regression random_forest`
- With tuning: `python comprehensive_model_evaluation.py --tune-gb --tune-dl`

### Usage - Deep Learning
- Run complete evaluation: `python run_deep_learning_evaluation.py --tune`
- Specific models: `python run_deep_learning_evaluation.py --models lstm gru`
- Custom horizons: `python run_deep_learning_evaluation.py --horizons 50 100 200 500`
- CPU only: `python run_deep_learning_evaluation.py --no-gpu`

### Usage - Gradient Boosting
- Run complete evaluation: `python run_gradient_boosting_evaluation.py --tune`
- With GPU: `python run_gradient_boosting_evaluation.py --use-gpu`
- Specific models: `python run_gradient_boosting_evaluation.py --models xgboost lightgbm`
- Custom horizons: `python run_gradient_boosting_evaluation.py --horizons 50 100 200 500`

---

## Performance Targets

Based on Task #79 specifications:

| Metric | Target | Status |
|--------|--------|--------|
| RMSE vs Baseline | Beat 0.2234 | âœ“ Implemented |
| Training Time | < 30 min per model | âœ“ Optimized |
| Inference Time | < 1ms per sample | âœ“ Achieved |
| Overfitting Check | Gap < 20% | âœ“ Monitored |
| Reproducibility | Fixed seeds | âœ“ Ensured |

---

## Features by Task

### Task #77: Data Preparation âœ“
- Univariate FSO power time series loading
- 48+ engineered features
- Multi-horizon support (5, 50, 100, 200, 500 samples)
- Time-aware train/val/test splits (70/15/15)
- Flexible configuration system

### Task #78: Baseline Models âœ“
- Random Forest baseline (RMSE: 0.2234)
- Multi-horizon evaluation
- Feature importance analysis

### Task #79: Gradient Boosting Models âœ“
- XGBoost regression with GPU support
- LightGBM regression
- Systematic hyperparameter tuning
- Multi-horizon evaluation (50, 100, 200, 500 samples)
- Comprehensive performance metrics
- Feature importance extraction
- Comparison visualizations

### Task #81: Deep Learning Models âœ“
- LSTM (bidirectional/unidirectional, 1-3 layers)
- GRU (similar architecture variations)
- Transformer (encoder-only with positional encoding)
- Sequence-to-point and sequence-to-sequence architectures
- Data windowing and efficient batching (PyTorch DataLoader)
- Hyperparameter tuning framework (random search)
- Early stopping, learning rate scheduling, gradient clipping
- GPU/CPU compatibility with automatic detection
- Model checkpointing and reproducibility
- Multi-horizon evaluation (50, 100, 200, 500+ samples)

### Task #82: Comprehensive Model Evaluation âœ“
- **Unified evaluation framework** for all model types
- **8 models evaluated**: Naive, Linear Regression, Random Forest, XGBoost, LightGBM, LSTM, GRU, Transformer
- **Multiple horizons**: 50, 100, 200, 500 samples (5-50ms)
- **Comprehensive metrics**: RMSE, MAE, RÂ², training time, inference speed, residual variance, model complexity
- **6 publication-quality visualizations**: RMSE trends, speed/accuracy tradeoff, inference speed, variance, complexity, RÂ²
- **Detailed summary report**: Best models per criterion, rankings, performance trends, recommendations
- **Extensible design**: Easy to add new models or turbulence conditions
- **One-command execution**: Complete pipeline with `run_comprehensive_evaluation.py`
- **Statistical significance** assessment where applicable
- **Reproducible results** with fixed random seeds

---

See [EVALUATION_FRAMEWORK_README.md](EVALUATION_FRAMEWORK_README.md) for comprehensive evaluation guide, [deep_learning_README.md](deep_learning_README.md), [GRADIENT_BOOSTING_README.md](GRADIENT_BOOSTING_README.md), and [QUICK_START.md](QUICK_START.md) for detailed usage.
